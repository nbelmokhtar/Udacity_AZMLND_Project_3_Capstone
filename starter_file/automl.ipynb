{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML\n",
    "\n",
    "Import of all the dependencies that we need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598423888013
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "import azureml.core\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "from sklearn.model_selection import train_test_split\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "Dataset from Davide Chicco, Giuseppe Jurman: Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone. BMC Medical Informatics and Decision Making 20, 16 (2020)\n",
    "\n",
    "Heart failure is a common event caused by Cardiovascular diseases (CVDs) and this dataset contains 12 features that can be used to predict mortality by heart failure.\n",
    "\n",
    "01- age : Age of the patient (years)\n",
    "02- anaemia : Decrease of red blood cells or hemoglobin (boolean)\n",
    "03- creatinine_phosphokinase : Level of the CPK enzyme in the blood (mcg/L)\n",
    "04- diabetes : If the patient has diabetes (boolean)\n",
    "05- ejection_fraction : Percentage of blood leaving the heart at each contraction (percentage)\n",
    "06- high_blood_pressure : If the patient has hypertension (boolean)\n",
    "07- platelets : Platelets in the blood (kiloplatelets/mL)\n",
    "08- serum_creatinine : Level of serum creatinine in the blood (mg/dL)\n",
    "09- serum_sodium :Level of serum sodium in the blood (mEq/L)\n",
    "10- sex : Woman or man (binary)\n",
    "11- smoking : If the patient smokes or not (boolean)\n",
    "12- time : Follow-up period (days)\n",
    "\n",
    "### Task\n",
    "\n",
    "An Azure Auto ML will be performed to predict if the patient deceased during the follow-up period (DEATH_EVENT : boolean), based on the 12 clinical features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to a workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598423890461
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Azure ML experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a name for experiment\n",
    "experiment_name = 'automl_heart_failure_experiment'\n",
    "project_folder = './automl-model'\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "experiment\n",
    "run = experiment.start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set was downloaded as a csv file and registered as data set in the workspace\n",
    "dataset=Dataset.get_by_name(ws,name=\"heart_failure_clinical_records_dataset\")\n",
    "df = dataset.to_pandas_dataframe()\n",
    "df.describe()\n",
    "dataset.take(5).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currDir=os.getcwd()\n",
    "print(currDir)\n",
    "os.listdir(currDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or Attach a Compute Resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create compute cluster\n",
    "# Use vm_size = \"STANDARD_D12_V2\" in provisioning configuration.\n",
    "# max_nodes 6.\n",
    "\n",
    "# Choose a name for CPU cluster\n",
    "cluster_name = \"my-cpu-cluster\"\n",
    "\n",
    "# Check if the compute target exists\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target, use it')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_D2_V2', \n",
    "                                                           max_nodes=6)\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# get a detailed status for the current cluster\n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "We didn't explicitly specified either a validation_data or n_cross_validation parameter, automated ML applies default techniques depending on the number of rows provided in the single training_data=dataset. Dataset is less than 1,000 rows, 10 folds are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598429217746
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# AutoML settings\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\": 30,\n",
    "    \"max_concurrent_iterations\": 5,\n",
    "    \"primary_metric\" : 'accuracy',\n",
    "}\n",
    "\n",
    "# AutoML config\n",
    "automl_config = AutoMLConfig(compute_target=compute_target,\n",
    "                             task = \"classification\",\n",
    "                             training_data=dataset,\n",
    "                             label_column_name=\"DEATH_EVENT\",   \n",
    "                             path = project_folder,\n",
    "                             enable_early_stopping= True,\n",
    "                             debug_log = \"automl_errors.log\",\n",
    "                             **automl_settings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431107951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit the experiment\n",
    "remote_run = experiment.submit(automl_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "Using the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "RunDetails(remote_run).show()\n",
    "remote_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "Getting the best model from the automl experiments and displaying all the properties of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431425670
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve and save the best automl model.\n",
    "automl_best_run, fitted_automl_best_model = remote_run.get_output()\n",
    "best_run_metrics = automl_best_run.get_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=========================== Best Run ID ===========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_best_run.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=========================== Best Run ===========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=========================== Best Model ===========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_automl_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=========================== Best Run File Names ===========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_best_run.get_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=========================== Best Run Metrics ===========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric in best run\n",
    "\n",
    "for metric_name in best_run_metrics:\n",
    "    metric = best_run_metrics[metric_name]\n",
    "    print(metric_name, metric)\n",
    "    \n",
    "print('\\nAccuracy of Best Run',best_run_metrics['accuracy'],sep='\\n')\n",
    "print(automl_best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=========================== Best Run Properties ===========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = automl_best_run.properties['model_name']\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431426111
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Save the best model\n",
    "\n",
    "os.makedirs('./outputs', exist_ok=True)\n",
    "joblib.dump(fitted_automl_best_model, filename='outputs/automl_best_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Environment\n",
    "\n",
    "env = automl_best_run.get_environment()\n",
    "\n",
    "script_file_name = 'score.py'\n",
    "automl_best_model.download_file('outputs/scoring_file_v_1_0_0.py', script_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "We have to deploy only one of the two models we trained.\n",
    "\n",
    "In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431435189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Register the model\n",
    "\n",
    "description = 'AutoML Model trained on heart failure dataset to predict if the patient deceased during the follow-up period'\n",
    "tags = None\n",
    "model = remote_run.register_model(model_name=model_name, description=description, tags=tags)\n",
    "print(model.name, model.id, model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an inference config and deploy the model as a web service on Azure Container Instance\n",
    "\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=script_file_name, environment=env)\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 2, \n",
    "                                                       memory_gb = 2\n",
    "                                                       tags = {'area': \"heart_failure\", 'type': \"automl_classification\"}, \n",
    "                                                       description = 'sample service for Automl Classification',\n",
    "                                                       auth_enabled = True,\n",
    "                                                       primary_key = 'iOhff5Z0kJlzznr9Wq4c3KcGQULltKYB')\n",
    "\n",
    "deploy_service_name= 'automl-heart-failure-model-deployment'\n",
    "service = Model.deploy(ws,deploy_service_name,  [model], inference_config, deployment_config)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "\n",
    "scoring_uri = service.scoring_uri\n",
    "\n",
    "print(deploy_service_name)\n",
    "print(\"\\nState: \",service.state)\n",
    "print(\"\\nScoring URI: \", scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.update(enable_app_insights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Sending a request to the web service we deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "scoring_uri = 'http://973f9601-a8f9-4bd4-9ade-76ee4b5d8d78.southcentralus.azurecontainer.io/score'\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "test_data_1 = json.dumps({'data':[{\n",
    "    'age':75,\n",
    "    'anaemia':0,\n",
    "    'creatinine_phosphokinase':582,\n",
    "    'diabetes':0,\n",
    "    'ejection_fraction':20,\n",
    "    'high_blood_pressure':1,\n",
    "    'platelets':265000,\n",
    "    'serum_creatinine':1.9,\n",
    "    'serum_sodium':130,\n",
    "    'sex':1,\n",
    "    'smoking':0,\n",
    "    'time':4}\n",
    "    ]\n",
    "        })\n",
    "\n",
    "test_data_2 = json.dumps({'data':[{\n",
    "    'age':40,\n",
    "    'anaemia':0,\n",
    "    'creatinine_phosphokinase':321,\n",
    "    'diabetes':0,\n",
    "    'ejection_fraction':35,\n",
    "    'high_blood_pressure':0,\n",
    "    'platelets':265000,\n",
    "    'serum_creatinine':1,\n",
    "    'serum_sodium':130,\n",
    "    'sex':1,\n",
    "    'smoking':0,\n",
    "    'time':198}\n",
    "    ]\n",
    "        })\n",
    "\n",
    "\n",
    "response1 = requests.post(scoring_uri, data=test_data_1, headers=headers)\n",
    "\n",
    "print(\"Result 1:\",response1.text)\n",
    "\n",
    "response2 = requests.post(scoring_uri, data=test_data2_, headers=headers)\n",
    "\n",
    "print(\"Result 2:\",response2.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
